{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "corr_data = train_data.copy()\n",
    "\n",
    "train_data.replace({\n",
    "    \"X3\": {'Low Fat': 0, 'Regular': 1, 'low fat': 0, 'LF': 0, 'reg': 1},\n",
    "    \"X9\": {'Medium': 1, 'High': 2, 'Small': 0}\n",
    "}, inplace=True)\n",
    "\n",
    "test_data.replace({\n",
    "    \"X3\": {'Low Fat': 0, 'Regular': 1, 'low fat': 0, 'LF': 0, 'reg': 1},\n",
    "    \"X9\": {'Medium': 1, 'High': 2, 'Small': 0}\n",
    "}, inplace=True)\n",
    "\n",
    "for column in train_data.columns:\n",
    "    train_data[column].fillna(train_data[column].mode()[0], inplace=True)\n",
    "\n",
    "for column in test_data.columns:\n",
    "    test_data[column].fillna(test_data[column].mode()[0], inplace=True)\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=['X11', 'X7'], prefix=['X11', 'X7'])\n",
    "test_data = pd.get_dummies(test_data, columns=['X11', 'X7'], prefix=['X11', 'X7'])\n",
    "\n",
    "train_data = train_data[['X2', 'X3', 'X4', 'X6', 'X7_OUT010', 'X7_OUT019', 'X7_OUT027', \n",
    "                         'X8', 'X9', 'X11_Grocery Store', 'X11_Supermarket Type1', \n",
    "                         'X11_Supermarket Type3','Y']]\n",
    "test_data = test_data[['X2', 'X3', 'X4', 'X6', 'X7_OUT010', 'X7_OUT019', 'X7_OUT027', \n",
    "                       'X8', 'X9', 'X11_Grocery Store', 'X11_Supermarket Type1', \n",
    "                       'X11_Supermarket Type3']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(x =train_data[\"X2\"], kde=True, bins=30)\n",
    "plt.title('Histogram of X2')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.histplot(x=train_data[\"X6\"], kde=True, bins=30)\n",
    "plt.title('Histogram of X6')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal')\n",
    "train_data[[\"X2\", \"X6\"]] = quantile_transformer.fit_transform(train_data[[\"X2\", \"X6\"]])\n",
    "test_data[[\"X2\", \"X6\"]] = quantile_transformer.transform(test_data[[\"X2\", \"X6\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x =train_data[\"X2\"], kde=True, bins=30)\n",
    "plt.title('Histogram of X2 fter transformation')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.histplot(x=train_data[\"X6\"], kde=True, bins=30)\n",
    "plt.title('Histogram of X6 after transformation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data[[\"X2\", \"X6\", \"X8\"]] = scaler.fit_transform(train_data[[\"X2\", \"X6\", \"X8\"]])\n",
    "test_data[[\"X2\", \"X6\", \"X8\"]] = scaler.transform(test_data[[\"X2\", \"X6\", \"X8\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data.to_csv(\"train_preprocessed.csv\", index=False)\n",
    "test_data.to_csv(\"test_preprocessed.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 1: Load the preprocessed train and test data\n",
    "train_data = pd.read_csv(\"train_preprocessed.csv\")\n",
    "test_data = pd.read_csv(\"test_preprocessed.csv\")\n",
    "\n",
    "# Step 2: Prepare the data for Linear Regression\n",
    "X_train = train_data.drop('Y', axis=1)  # Features for training\n",
    "y_train = train_data['Y']  # Target variable for training\n",
    "\n",
    "X_test = test_data  # Features for testing (target 'Y' is not available)\n",
    "\n",
    "# Step 3: Create and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)  # Train the model on the training data\n",
    "\n",
    "# Step 4: Make predictions on the test data\n",
    "y_pred = model.predict(X_test)  # Predict the target values for the test data\n",
    "\n",
    "# Step 5: Save the predictions to a new CSV file (since we don't have ground truth for test data)\n",
    "test_data['Y_pred'] = y_pred  # Add the predicted values as a new column in the test data\n",
    "\n",
    "# Save the test data with predictions to a new CSV file\n",
    "test_data.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_train, y_pred, alpha=0.6, color=\"blue\")  \n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2) \n",
    "plt.title(\"Actual vs Predicted Values\")\n",
    "plt.xlabel(\"Actual Values (y_train)\")\n",
    "plt.ylabel(\"Predicted Values (y_pred)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X3 is Binary\")\n",
    "print(original_data['X3'].unique())\n",
    "print(\"=\"*10)\n",
    "print(\"X9 is ordinal\")\n",
    "print(original_data['X9'].unique())\n",
    "print(\"=\"*10)\n",
    "print(\"X5 is nominal \")\n",
    "print(original_data['X5'].unique())\n",
    "print(\"=\"*10)\n",
    "print(\"X7 is nominal \")\n",
    "print(original_data['X7'].unique())\n",
    "print(\"=\"*10)\n",
    "print(\"X10 is nominal \")\n",
    "print(original_data['X10'].unique())\n",
    "print(\"=\"*10)\n",
    "print(\"X11 is nominal \")\n",
    "print(original_data['X11'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can try:\n",
    "\n",
    "## Feature Relations\n",
    "\n",
    "## Standardization\n",
    "\n",
    "## iterative imputer\n",
    "\n",
    "## knn imputer\n",
    "\n",
    "## label encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
